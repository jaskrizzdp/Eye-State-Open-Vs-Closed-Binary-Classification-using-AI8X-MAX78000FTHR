// // /*******************************************************************************
// // * Copyright (C) 2019-2023 Maxim Integrated Products, Inc., All rights Reserved.
// // *
// // * This software is protected by copyright laws of the United States and
// // * of foreign countries. This material may also be protected by patent laws
// // * and technology transfer regulations of the United States and of foreign
// // * countries. This software is furnished under a license agreement and/or a
// // * nondisclosure agreement and may only be used or reproduced in accordance
// // * with the terms of those agreements. Dissemination of this information to
// // * any party or parties not specified in the license agreement and/or
// // * nondisclosure agreement is expressly prohibited.
// // *
// // * The above copyright notice and this permission notice shall be included
// // * in all copies or substantial portions of the Software.
// // *
// // * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// // * OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// // * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
// // * IN NO EVENT SHALL MAXIM INTEGRATED BE LIABLE FOR ANY CLAIM, DAMAGES
// // * OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
// // * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
// // * OTHER DEALINGS IN THE SOFTWARE.
// // *
// // * Except as contained in this notice, the name of Maxim Integrated
// // * Products, Inc. shall not be used except as stated in the Maxim Integrated
// // * Products, Inc. Branding Policy.
// // *
// // * The mere transfer of this software does not imply any licenses
// // * of trade secrets, proprietary technology, copyrights, patents,
// // * trademarks, maskwork rights, or any other form of intellectual
// // * property whatsoever. Maxim Integrated Products, Inc. retains all
// // * ownership rights.
// // *******************************************************************************/

// // // eyes
// // // This file was @generated by ai8xize.py --test-dir C:/MaximSDK/Examples/MAX78000/CNN --prefix eyes --checkpoint-file ../ai8x-training/logs/2025.12.30-033219/eyes-qat8-q.pth.tar --config-file networks/eyes-hwc.yaml --sample-input ../ai8x-training/logs/2025.12.30-033219/sample_eyes.npy --fifo --softmax --device MAX78000 --timer 0 --display-checkpoint --verbose

// // #include <stdlib.h>
// // #include <stdint.h>
// // #include <string.h>
// // #include <stdio.h>
// // #include "mxc.h"
// // #include "cnn.h"
// // #include "sampledata.h"
// // #include "sampleoutput.h"

// // volatile uint32_t cnn_time; // Stopwatch

// // void fail(void)
// // {
// //   printf("\n*** FAIL ***\n\n");
// //   while (1);
// // }

// // // Data input: HWC 3x128x128 (49152 bytes total / 16384 bytes per channel):
// // static const uint32_t input_0[] = SAMPLE_INPUT_0;
// // void load_input(void)
// // {
// //   // This function loads the sample data input -- replace with actual data

// //   int i;
// //   const uint32_t *in0 = input_0;

// //   for (i = 0; i < 16384; i++) {
// //     // Remove the following line if there is no risk that the source would overrun the FIFO:
// //     while (((*((volatile uint32_t *) 0x50000004) & 1)) != 0); // Wait for FIFO 0
// //     *((volatile uint32_t *) 0x50000008) = *in0++; // Write FIFO 0
// //   }
// // }

// // // Expected output of layer 6 for eyes given the sample input (known-answer test)
// // // Delete this function for production code
// // static const uint32_t sample_output[] = SAMPLE_OUTPUT;
// // int check_output(void)
// // {
// //   int i;
// //   uint32_t mask, len;
// //   volatile uint32_t *addr;
// //   const uint32_t *ptr = sample_output;

// //   while ((addr = (volatile uint32_t *) *ptr++) != 0) {
// //     mask = *ptr++;
// //     len = *ptr++;
// //     for (i = 0; i < len; i++)
// //       if ((*addr++ & mask) != *ptr++) {
// //         printf("Data mismatch (%d/%d) at address 0x%08x: Expected 0x%08x, read 0x%08x.\n",
// //                i + 1, len, addr - 1, *(ptr - 1), *(addr - 1) & mask);
// //         return CNN_FAIL;
// //       }
// //   }

// //   return CNN_OK;
// // }

// // // Classification layer:
// // static int32_t ml_data[CNN_NUM_OUTPUTS];
// // static q15_t ml_softmax[CNN_NUM_OUTPUTS];

// // void softmax_layer(void)
// // {
// //   cnn_unload((uint32_t *) ml_data);
// //   softmax_q17p14_q15((const q31_t *) ml_data, CNN_NUM_OUTPUTS, ml_softmax);
// // }

// // int main(void)
// // {
// //   int i;
// //   int digs, tens;

// //   MXC_ICC_Enable(MXC_ICC0); // Enable cache

// //   // Switch to 100 MHz clock
// //   MXC_SYS_Clock_Select(MXC_SYS_CLOCK_IPO);
// //   SystemCoreClockUpdate();

// //   printf("Waiting...\n");

// //   // DO NOT DELETE THIS LINE:
// //   MXC_Delay(SEC(2)); // Let debugger interrupt if needed

// //   // Enable peripheral, enable CNN interrupt, turn on CNN clock
// //   // CNN clock: APB (50 MHz) div 1
// //   cnn_enable(MXC_S_GCR_PCLKDIV_CNNCLKSEL_PCLK, MXC_S_GCR_PCLKDIV_CNNCLKDIV_DIV1);

// //   printf("\n*** CNN Inference Test eyes ***\n");

// //   cnn_init(); // Bring state machine into consistent state
// //   cnn_load_weights(); // Load kernels
// //   cnn_load_bias();
// //   cnn_configure(); // Configure state machine
// //   cnn_start(); // Start CNN processing
// //   load_input(); // Load data input via FIFO

// //   while (cnn_time == 0)
// //     MXC_LP_EnterSleepMode(); // Wait for CNN

// //   if (check_output() != CNN_OK) fail();
// //   softmax_layer();

// //   printf("\n*** PASS ***\n\n");

// // #ifdef CNN_INFERENCE_TIMER
// //   printf("Approximate data loading and inference time: %u us\n\n", cnn_time);
// // #endif

// //   cnn_disable(); // Shut down CNN clock, disable peripheral

// //   printf("Classification results:\n");
// //   for (i = 0; i < CNN_NUM_OUTPUTS; i++) {
// //     digs = (1000 * ml_softmax[i] + 0x4000) >> 15;
// //     tens = digs % 10;
// //     digs = digs / 10;
// //     printf("[%7d] -> Class %d: %d.%d%%\n", ml_data[i], i, digs, tens);
// //   }

// //   return 0;
// // }

// // /*
// //   SUMMARY OF OPS
// //   Hardware: 51,368,960 ops (50,432,000 macc; 936,960 comp; 0 add; 0 mul; 0 bitwise)
// //     Layer 0: 7,340,032 ops (7,077,888 macc; 262,144 comp; 0 add; 0 mul; 0 bitwise)
// //     Layer 1: 19,267,584 ops (18,874,368 macc; 393,216 comp; 0 add; 0 mul; 0 bitwise)
// //     Layer 2: 19,070,976 ops (18,874,368 macc; 196,608 comp; 0 add; 0 mul; 0 bitwise)
// //     Layer 3: 4,792,320 ops (4,718,592 macc; 73,728 comp; 0 add; 0 mul; 0 bitwise)
// //     Layer 4: 600,064 ops (589,824 macc; 10,240 comp; 0 add; 0 mul; 0 bitwise)
// //     Layer 5: 295,936 ops (294,912 macc; 1,024 comp; 0 add; 0 mul; 0 bitwise)
// //     Layer 6: 2,048 ops (2,048 macc; 0 comp; 0 add; 0 mul; 0 bitwise)

// //   RESOURCE USAGE
// //   Weight memory: 57,776 bytes out of 442,368 bytes total (13.1%)
// //   Bias memory:   2 bytes out of 2,048 bytes total (0.1%)
// // */














// // /*******************************************************************************
// // * Copyright (C) 2019-2023 Maxim Integrated Products, Inc., All rights Reserved.
// // * (now owned by Analog Devices, Inc.)
// // *
// // * This file merges an ai8xize-generated CNN runtime (eyes) with MAX78000FTHR
// // * camera capture (RGB888 streaming DMA) for live inference.
// // *******************************************************************************/

// // #include <stdlib.h>
// // #include <stdint.h>
// // #include <string.h>
// // #include <stdio.h>

// // #include "mxc.h"
// // #include "cnn.h"

// // // MAX78000 SDK utilities
// // #include "mxc_device.h"
// // #include "mxc_sys.h"
// // #include "icc.h"
// // #include "mxc_delay.h"
// // #include "dma.h"
// // #include "led.h"
// // #include "pb.h"
// // #include "camera.h"

// // // -----------------------------------------------------------------------------
// // // Camera + Model Settings
// // // -----------------------------------------------------------------------------
// // #define IMAGE_SIZE_X (128)
// // #define IMAGE_SIZE_Y (128)
// // #define CAMERA_FREQ  (5 * 1000 * 1000) // 5 MHz

// // // If you want "press button to capture", keep this enabled.
// // // If you want continuous loop without button, comment this out.
// // #define USE_PB_TRIGGER

// // // -----------------------------------------------------------------------------
// // // Globals
// // // -----------------------------------------------------------------------------
// // volatile uint32_t cnn_time; // set by CNN ISR

// // // CNN output buffers
// // static int32_t ml_data[CNN_NUM_OUTPUTS];
// // static q15_t ml_softmax[CNN_NUM_OUTPUTS];

// // // Camera -> CNN input buffer (1 word per pixel)
// // // Packed as 0x00BBGGRR then XOR 0x00808080 to shift to signed range
// // static uint32_t input_0[IMAGE_SIZE_X * IMAGE_SIZE_Y];

// // // Optional RGB565 buffer if you later want TFT output (not used here)
// // static uint8_t data565[IMAGE_SIZE_X * 2];

// // // -----------------------------------------------------------------------------
// // // Helpers
// // // -----------------------------------------------------------------------------
// // static void fail(void)
// // {
// //     printf("\n*** FAIL ***\n\n");
// //     while (1) {
// //         __WFI();
// //     }
// // }

// // // Capture camera frame and fill input_0[] for CNN
// // static void capture_process_camera(void)
// // {
// //     uint8_t *raw;
// //     uint32_t imgLen;
// //     uint32_t w, h;

// //     int cnt = 0;
// //     uint8_t r, g, b;
// //     uint16_t rgb;
// //     int j;

// //     uint8_t *data = NULL;

// //     camera_start_capture_image();
// //     camera_get_image(&raw, &imgLen, &w, &h);

// //     // Basic sanity print (optional; comment out if too spammy)
// //     // printf("Camera frame: w=%lu h=%lu len=%lu\n", (unsigned long)w, (unsigned long)h, (unsigned long)imgLen);

// //     if (w != IMAGE_SIZE_X || h != IMAGE_SIZE_Y) {
// //         printf("ERROR: Camera resolution mismatch! got %lux%lu expected %dx%d\n",
// //                (unsigned long)w, (unsigned long)h, IMAGE_SIZE_X, IMAGE_SIZE_Y);
// //         fail();
// //     }

// //     // Stream line-by-line from camera driver
// //     for (int row = 0; row < (int)h; row++) {
// //         while ((data = get_camera_stream_buffer()) == NULL) {
// //             if (camera_is_image_rcv()) {
// //                 break;
// //             }
// //         }
// //         if (data == NULL) {
// //             printf("ERROR: camera stream buffer NULL\n");
// //             fail();
// //         }

// //         j = 0;

// //         // Camera stream format used in many FTHR examples:
// //         // data per pixel spaced by 4 bytes: [R][G][B][0x00]
// //         for (int k = 0; k < 4 * (int)w; k += 4) {
// //             r = data[k];
// //             g = data[k + 1];
// //             b = data[k + 2];
// //             // skip data[k+3]

// //             // Pack to 0x00BBGGRR and shift to signed by XOR with 0x00808080
// //             input_0[cnt++] = ((b << 16) | (g << 8) | r) ^ 0x00808080;

// //             // Optional: RGB565 conversion if you later display
// //             rgb = ((r & 0b11111000) << 8) | ((g & 0b11111100) << 3) | (b >> 3);
// //             data565[j++] = (rgb >> 8) & 0xFF;
// //             data565[j++] = rgb & 0xFF;
// //         }

// //         release_camera_stream_buffer();
// //     }
// // }

// // // Write camera buffer into CNN FIFO (16384 words = 128*128)
// // static void load_input(void)
// // {
// //     const uint32_t *in0 = input_0;

// //     for (int i = 0; i < (IMAGE_SIZE_X * IMAGE_SIZE_Y); i++) {
// //         // Wait for FIFO 0 not full
// //         while ((*((volatile uint32_t *)0x50000004) & 1) != 0) {
// //         }
// //         // Write FIFO 0
// //         *((volatile uint32_t *)0x50000008) = *in0++;
// //     }
// // }

// // static void softmax_layer(void)
// // {
// //     cnn_unload((uint32_t *)ml_data);
// //     softmax_q17p14_q15((const q31_t *)ml_data, CNN_NUM_OUTPUTS, ml_softmax);
// // }

// // // -----------------------------------------------------------------------------
// // // Main
// // // -----------------------------------------------------------------------------
// // int main(void)
// // {
// //     int ret;
// //     int dma_channel;

// //     // Optional class names (edit these to match your eyes model)
// //     // If you don't know labels yet, leave as Class0.. etc.
// //     const char *classes[CNN_NUM_OUTPUTS] = {
// //         "Class0",
// //         "Class1",
// //         "Class2",
// //         "Class3",
// //         "Class4",
// //         "Class5",
// //         "Class6",
// //         "Class7",
// //     };

// // #if defined(BOARD_FTHR_REVA)
// //     // Some Feather revisions use this for camera power-on timing
// //     MXC_Delay(200000);
// //     Camera_Power(POWER_ON);
// // #endif

// //     MXC_ICC_Enable(MXC_ICC0);

// //     // Switch to 100 MHz clock
// //     MXC_SYS_Clock_Select(MXC_SYS_CLOCK_IPO);
// //     SystemCoreClockUpdate();

// //     printf("eyes (camera) starting...\n");

// //     // Let debugger attach if needed
// //     MXC_Delay(SEC(2));

// //     // -------------------------
// //     // CNN init
// //     // -------------------------
// //     cnn_enable(MXC_S_GCR_PCLKDIV_CNNCLKSEL_PCLK,
// //                MXC_S_GCR_PCLKDIV_CNNCLKDIV_DIV1);

// //     cnn_init();
// //     cnn_load_weights();
// //     cnn_load_bias();
// //     cnn_configure();

// //     // -------------------------
// //     // Camera init (DMA streaming)
// //     // -------------------------
// //     MXC_DMA_Init();
// //     dma_channel = MXC_DMA_AcquireChannel();

// //     printf("Init Camera...\n");
// //     camera_init(CAMERA_FREQ);

// //     ret = camera_setup(IMAGE_SIZE_X, IMAGE_SIZE_Y,
// //                        PIXFORMAT_RGB888,
// //                        FIFO_THREE_BYTE,
// //                        STREAMING_DMA,
// //                        dma_channel);

// //     if (ret != STATUS_OK) {
// //         printf("ERROR: camera_setup failed (%d)\n", ret);
// //         fail();
// //     }

// //     // Common sensor tweak in examples
// //     camera_write_reg(0x11, 0x0);

// //     // Enable CNN peripheral clock explicitly (some examples do this)
// //     MXC_SYS_ClockEnable(MXC_SYS_PERIPH_CLOCK_CNN);

// // #ifdef USE_PB_TRIGGER
// //     printf("Press PB1 (SW1) to capture and infer...\n");
// //     while (!PB_Get(0)) {
// //     }
// // #else
// //     printf("Running continuous inference...\n");
// // #endif

// //     // -------------------------
// //     // Inference loop
// //     // -------------------------
// //     while (1) {
// //         // Visual heartbeat (optional)
// //         LED_Off(LED1);
// //         LED_Off(LED2);

// //         // Capture a frame
// //         capture_process_camera();

// //         // Start CNN + push pixels
// //         cnn_time = 0;
// //         cnn_start();
// //         load_input();

// //         // Wait for CNN interrupt
// //         while (cnn_time == 0) {
// //             __WFI();
// //         }

// //         // Read output + softmax
// //         softmax_layer();

// //         // Print results
// //         printf("\n--- eyes classification ---\n");
// // #ifdef CNN_INFERENCE_TIMER
// //         printf("cnn_time = %u us\n", (unsigned)cnn_time);
// // #endif
// //         for (int i = 0; i < CNN_NUM_OUTPUTS; i++) {
// //             int pct10 = (1000 * ml_softmax[i] + 0x4000) >> 15; // tenths of %
// //             const char *name = (i < (int)(sizeof(classes) / sizeof(classes[0]))) ? classes[i] : "Class";
// //             printf("[%7ld] -> %-12s : %d.%d%%\n",
// //                    (long)ml_data[i],
// //                    name,
// //                    pct10 / 10, pct10 % 10);
// //         }

// //         LED_On(LED1);

// // #ifdef USE_PB_TRIGGER
// //         printf("\nPress PB1 (SW1) again...\n");
// //         while (!PB_Get(0)) {
// //         }
// //         // Simple debounce
// //         MXC_Delay(MSEC(200));
// // #else
// //         MXC_Delay(MSEC(500));
// // #endif
// //     }
// // }













// /******************************************************************************
//  *
//  * Eyes classification with camera capture, PB1 button, TFT display, CNN
//  * Inherits Cats-vs-Dogs demo functionality but uses Eyes model
//  *
//  ******************************************************************************/

// #include <stdlib.h>
// #include <stdint.h>
// #include <string.h>
// #include <stdio.h>
// #include "mxc_device.h"
// #include "mxc_sys.h"
// #include "fcr_regs.h"
// #include "icc.h"
// #include "led.h"
// #include "tmr.h"
// #include "dma.h"
// #include "pb.h"
// #include "cnn.h"
// #include "weights.h"
// #include "sampleoutput.h"
// #include "mxc_delay.h"
// #include "camera.h"

// #ifdef BOARD_EVKIT_V1
// #include "bitmap.h"
// #include "tft_ssd2119.h"
// #endif
// #ifdef BOARD_FTHR_REVA
// #include "tft_ili9341.h"
// #endif

// #define ASCII_ART

// #define IMAGE_SIZE_X 128
// #define IMAGE_SIZE_Y 128
// #define TFT_X_START 100
// #define TFT_Y_START 50
// #define CAMERA_FREQ (5 * 1000 * 1000)
// #define TFT_BUFF_SIZE 30

// #ifdef BOARD_EVKIT_V1
// int image_bitmap_1 = ADI_256_bmp;
// int image_bitmap_2 = logo_white_bg_darkgrey_bmp;
// int font_1 = urw_gothic_12_white_bg_grey;
// int font_2 = urw_gothic_13_white_bg_grey;
// #endif
// #ifdef BOARD_FTHR_REVA
// int image_bitmap_1 = (int)&img_1_rgb565[0];
// int image_bitmap_2 = (int)&logo_rgb565[0];
// int font_1 = (int)&Liberation_Sans16x16[0];
// int font_2 = (int)&Liberation_Sans16x16[0];
// #endif

// // Eyes classification labels (replace with your actual labels)
// const char classes[CNN_NUM_OUTPUTS][10] = { "Open", "Closed" };

// // Classification layer
// static int32_t ml_data[CNN_NUM_OUTPUTS];
// static q15_t ml_softmax[CNN_NUM_OUTPUTS];

// volatile uint32_t cnn_time; // Stopwatch

// // RGB565 buffer for TFT
// uint8_t data565[IMAGE_SIZE_X * 2 * 2];

// // Camera input buffer
// static uint32_t input_0[IMAGE_SIZE_X * IMAGE_SIZE_Y]; // camera fills this

// /* **************************************************************************** */
// #ifdef ASCII_ART
// char *brightness = "@%#*+=-:. ";
// #define RATIO 2
// void asciiart(uint8_t *img)
// {
//     int skip_x, skip_y;
//     uint8_t r, g, b, Y;
//     uint8_t *srcPtr = img;
//     int l = strlen(brightness) - 1;

//     skip_x = RATIO;
//     skip_y = RATIO;
//     for (int i = 0; i < IMAGE_SIZE_Y; i++) {
//         for (int j = 0; j < IMAGE_SIZE_X; j++) {
//             r = *srcPtr++ ^ 0x80;
//             g = *srcPtr++ ^ 0x80;
//             b = *srcPtr++ ^ 0x80;
//             srcPtr++;
//             Y = (3 * r + b + 4 * g) >> 3;
//             if ((skip_x == RATIO) && (skip_y == RATIO))
//                 printf("%c", brightness[l - (Y * l / 255)]);

//             skip_x++;
//             if (skip_x > RATIO) skip_x = 1;
//         }
//         skip_y++;
//         if (skip_y > RATIO) {
//             printf("\n");
//             skip_y = 1;
//         }
//     }
// }
// #endif

// /* **************************************************************************** */
// #ifdef TFT_ENABLE
// void TFT_Print(char *str, int x, int y, int font, int length)
// {
//     text_t text;
//     text.data = str;
//     text.len = length;
//     MXC_TFT_PrintFont(x, y, font, &text, NULL);
// }

// int g_dma_channel_tft = 1;
// void setup_dma_tft(uint32_t *src_ptr, uint16_t byte_cnt)
// {
//     while ((MXC_DMA->ch[g_dma_channel_tft].status & MXC_F_DMA_STATUS_STATUS)) {}

//     MXC_DMA->ch[g_dma_channel_tft].status = MXC_F_DMA_STATUS_CTZ_IF;
//     MXC_DMA->ch[g_dma_channel_tft].dst = (uint32_t)data565;
//     MXC_DMA->ch[g_dma_channel_tft].src = (uint32_t)src_ptr;
//     MXC_DMA->ch[g_dma_channel_tft].cnt = byte_cnt;

//     MXC_DMA->ch[g_dma_channel_tft].ctrl =
//         ((0x1 << MXC_F_DMA_CTRL_CTZ_IE_POS) +
//          (0x0 << MXC_F_DMA_CTRL_DIS_IE_POS) +
//          (0x1 << MXC_F_DMA_CTRL_BURST_SIZE_POS) +
//          (0x0 << MXC_F_DMA_CTRL_DSTINC_POS) +
//          (0x1 << MXC_F_DMA_CTRL_DSTWD_POS) +
//          (0x1 << MXC_F_DMA_CTRL_SRCINC_POS) +
//          (0x1 << MXC_F_DMA_CTRL_SRCWD_POS) +
//          (0x0 << MXC_F_DMA_CTRL_TO_CLKDIV_POS) +
//          (0x0 << MXC_F_DMA_CTRL_TO_WAIT_POS) +
//          (0x2F << MXC_F_DMA_CTRL_REQUEST_POS) +
//          (0x0 << MXC_F_DMA_CTRL_PRI_POS) +
//          (0x0 << MXC_F_DMA_CTRL_RLDEN_POS));

//     MXC_SPI0->ctrl0 &= ~(MXC_F_SPI_CTRL0_EN);
//     MXC_SETFIELD(MXC_SPI0->ctrl1, MXC_F_SPI_CTRL1_TX_NUM_CHAR,
//                  byte_cnt << MXC_F_SPI_CTRL1_TX_NUM_CHAR_POS);
//     MXC_SPI0->dma |= (MXC_F_SPI_DMA_TX_FLUSH | MXC_F_SPI_DMA_RX_FLUSH);
//     MXC_SPI0->intfl = MXC_F_SPI_INTFL_MST_DONE;
//     MXC_SETFIELD(MXC_SPI0->dma, MXC_F_DMA_CTRL_EN_POS, 0x10);
//     MXC_SPI0->ctrl0 |= MXC_F_SPI_CTRL0_EN;
// }

// void tft_dma_display(int x, int y, int w, int h, uint32_t *data)
// {
//     setup_dma_tft(data, w * h * 2);
//     MXC_DMA->ch[g_dma_channel_tft].ctrl |= (0x1 << MXC_F_DMA_CTRL_EN_POS);
//     MXC_Delay(1);
//     MXC_SPI0->ctrl0 |= MXC_F_SPI_CTRL0_START;
// }
// #endif

// /* **************************************************************************** */
// void fail(void)
// {
//     printf("\n*** FAIL ***\n\n");
//     while (1) {}
// }

// /* **************************************************************************** */
// void capture_process_camera(void)
// {
//     uint8_t *raw, *data;
//     uint32_t imgLen, w, h;
//     int cnt = 0;
//     uint8_t r, g, b;
//     uint16_t rgb;
//     int j;

//     stream_stat_t *stat;

//     camera_start_capture_image();
//     camera_get_image(&raw, &imgLen, &w, &h);
//     printf("W:%d H:%d L:%d \n", w, h, imgLen);

// #if defined(TFT_ENABLE) && defined(BOARD_FTHR_REVA)
//     MXC_TFT_Stream(TFT_X_START, TFT_Y_START, w, h);
// #endif

//     for (int row = 0; row < h; row++) {
//         while ((data = get_camera_stream_buffer()) == NULL) {
//             if (camera_is_image_rcv()) break;
//         }

// #ifdef BOARD_EVKIT_V1
//         j = IMAGE_SIZE_X * 2 - 2;
// #else
//         j = 0;
// #endif

//         for (int k = 0; k < 4 * w; k += 4) {
//             r = data[k];
//             g = data[k + 1];
//             b = data[k + 2];
//             input_0[cnt++] = ((b << 16) | (g << 8) | r) ^ 0x00808080;
//             rgb = ((r & 0b11111000) << 8) | ((g & 0b11111100) << 3) | (b >> 3);
//             data565[j] = (rgb >> 8) & 0xFF;
//             data565[j + 1] = rgb & 0xFF;

// #ifdef BOARD_EVKIT_V1
//             j -= 2;
// #else
//             j += 2;
// #endif
//         }

// #ifdef TFT_ENABLE
// #ifdef BOARD_EVKIT_V1
//         MXC_TFT_ShowImageCameraRGB565(TFT_X_START, TFT_Y_START + row, data565, w, 1);
// #endif
// #ifdef BOARD_FTHR_REVA
//         tft_dma_display(TFT_X_START, TFT_Y_START + row, w, 1, (uint32_t *)data565);
// #endif
// #endif
//         release_camera_stream_buffer();
//     }

//     stat = get_camera_stream_statistic();
//     if (stat->overflow_count > 0) {
//         printf("OVERFLOW DISP = %d\n", stat->overflow_count);
//         LED_On(LED2);
//         while (1) {}
//     }
// }

// /* **************************************************************************** */
// int main(void)
// {
//     int i, digs, tens, result[CNN_NUM_OUTPUTS];
//     int ret, dma_channel;
//     char buff[TFT_BUFF_SIZE];

//     MXC_ICC_Enable(MXC_ICC0);
//     MXC_SYS_Clock_Select(MXC_SYS_CLOCK_IPO);
//     SystemCoreClockUpdate();

//     printf("\n\nEyes Classification Demo\n");

//     MXC_DMA_Init();
//     dma_channel = MXC_DMA_AcquireChannel();

//     MXC_Delay(200000);
//     Camera_Power(POWER_ON);

//     cnn_enable(MXC_S_GCR_PCLKDIV_CNNCLKSEL_PCLK, MXC_S_GCR_PCLKDIV_CNNCLKDIV_DIV1);
//     cnn_init();
//     cnn_load_weights();
//     cnn_load_bias();
//     cnn_configure();

// #ifdef TFT_ENABLE
//     MXC_TFT_Init(MXC_SPI0, 1, NULL, NULL);
//     MXC_TFT_SetRotation(ROTATE_270);
//     MXC_TFT_ShowImage(0, 0, image_bitmap_1);
//     MXC_TFT_SetForeGroundColor(WHITE);
//     MXC_Delay(1000000);
//     memset(buff, 32, TFT_BUFF_SIZE);
//     TFT_Print(buff, 55, 50, font_2, snprintf(buff, sizeof(buff), "ANALOG DEVICES"));
//     TFT_Print(buff, 55, 90, font_1, snprintf(buff, sizeof(buff), "Eyes Demo"));
//     TFT_Print(buff, 20, 130, font_2, snprintf(buff, sizeof(buff), "PRESS PB1(SW1) TO START!"));
// #endif

//     printf("********** Press PB1(SW1) to capture an image **********\r\n");
//     while (!PB_Get(0)) {}

// #ifdef TFT_ENABLE
//     MXC_TFT_ClearScreen();
// #endif

//     camera_init(CAMERA_FREQ);
//     ret = camera_setup(IMAGE_SIZE_X, IMAGE_SIZE_Y, PIXFORMAT_RGB888, FIFO_THREE_BYTE, STREAMING_DMA, dma_channel);
//     if (ret != STATUS_OK) {
//         printf("Error returned from camera_setup %d\n", ret);
//         return -1;
//     }

// #ifdef BOARD_EVKIT_V1
//     camera_write_reg(0x11, 0x1);
// #endif
// #ifdef BOARD_FTHR_REVA
//     camera_write_reg(0x11, 0x0);
// #endif

//     MXC_SYS_ClockEnable(MXC_SYS_PERIPH_CLOCK_CNN);

//     while (1) {
//         LED_Off(LED1);
//         LED_Off(LED2);

//         capture_process_camera();

//         cnn_start();
//         // Load camera buffer into CNN
//         for (i = 0; i < IMAGE_SIZE_X * IMAGE_SIZE_Y; i++) {
//             while (((*((volatile uint32_t *)0x50000004) & 1)) != 0) {}
//             *((volatile uint32_t *)0x50000008) = input_0[i];
//         }

//         while (cnn_time == 0) __WFI();

//         cnn_unload((uint32_t *)ml_data);
//         cnn_stop();
//         softmax_q17p14_q15((const q31_t *)ml_data, CNN_NUM_OUTPUTS, ml_softmax);

//         printf("Time for CNN: %d us\n\n", cnn_time);

//         printf("Classification results:\n");
//         for (i = 0; i < CNN_NUM_OUTPUTS; i++) {
//             digs = (1000 * ml_softmax[i] + 0x4000) >> 15;
//             tens = digs % 10;
//             digs = digs / 10;
//             result[i] = digs;
//             printf("[%7d] -> Class %d %8s: %d.%d%%\r\n", ml_data[i], i, classes[i], result[i], tens);
//         }

// #ifdef ASCII_ART
//         asciiart((uint8_t *)input_0);
// #endif

// #ifdef TFT_ENABLE
//         memset(buff, 32, TFT_BUFF_SIZE);
//         if (ml_data[0] > ml_data[1]) {
//             TFT_Print(buff, TFT_X_START + 10, TFT_Y_START - 30, font_1,
//                       snprintf(buff, sizeof(buff), "%s (%d%%)", classes[0], result[0]));
//             LED_On(LED1); LED_Off(LED2);
//         } else {
//             TFT_Print(buff, TFT_X_START + 10, TFT_Y_START - 30, font_1,
//                       snprintf(buff, sizeof(buff), "%s (%d%%)", classes[1], result[1]));
//             LED_Off(LED1); LED_On(LED2);
//         }
//         TFT_Print(buff, TFT_X_START + 40, TFT_Y_START + IMAGE_SIZE_Y + 10, font_1,
//                   snprintf(buff, sizeof(buff), "%dms", cnn_time / 1000));
//         TFT_Print(buff, 20, TFT_Y_START + IMAGE_SIZE_Y + 35, font_2,
//                   snprintf(buff, sizeof(buff), "PRESS PB1(SW1) TO CAPTURE"));
// #endif

//         printf("********** Press PB1(SW1) to capture an image **********\r\n");
//         while (!PB_Get(0)) {}
//     }

//     return 0;
// }











/******************************************************************************
 *
 * Eyes classification with camera capture, PB1 button, TFT display, CNN
 * Inherits Cats-vs-Dogs demo functionality but uses Eyes model
 *
 ******************************************************************************/

#include <stdlib.h>
#include <stdint.h>
#include <string.h>
#include <stdio.h>
#include "mxc_device.h"
#include "mxc_sys.h"
#include "fcr_regs.h"
#include "icc.h"
#include "led.h"
#include "tmr.h"
#include "dma.h"
#include "pb.h"
#include "cnn.h"
#include "weights.h"
#include "sampleoutput.h"
#include "mxc_delay.h"
#include "camera.h"

#ifdef BOARD_EVKIT_V1
#include "bitmap.h"
#include "tft_ssd2119.h"
#endif
#ifdef BOARD_FTHR_REVA
#include "tft_ili9341.h"
#endif

#define ASCII_ART

#define IMAGE_SIZE_X 128
#define IMAGE_SIZE_Y 128
#define TFT_X_START 100
#define TFT_Y_START 50
#define CAMERA_FREQ (5 * 1000 * 1000)
#define TFT_BUFF_SIZE 30

#ifdef BOARD_EVKIT_V1
int image_bitmap_1 = ADI_256_bmp;
int image_bitmap_2 = logo_white_bg_darkgrey_bmp;
int font_1 = urw_gothic_12_white_bg_grey;
int font_2 = urw_gothic_13_white_bg_grey;
#endif
#ifdef BOARD_FTHR_REVA
int image_bitmap_1 = (int)&img_1_rgb565[0];
int image_bitmap_2 = (int)&logo_rgb565[0];
int font_1 = (int)&Liberation_Sans16x16[0];
int font_2 = (int)&Liberation_Sans16x16[0];
#endif

// Eyes classification labels (replace with your actual labels)
const char classes[CNN_NUM_OUTPUTS][10] = { "Open", "Closed" };

// Classification layer
static int32_t ml_data[CNN_NUM_OUTPUTS];
static q15_t ml_softmax[CNN_NUM_OUTPUTS];

volatile uint32_t cnn_time; // Stopwatch

// RGB565 buffer for TFT
uint8_t data565[IMAGE_SIZE_X * 2 * 2];

// Camera input buffer
static uint32_t input_0[IMAGE_SIZE_X * IMAGE_SIZE_Y]; // camera fills this

/* **************************************************************************** */
#ifdef ASCII_ART
char *brightness = "@%#*+=-:. ";
#define RATIO 2
void asciiart(uint8_t *img)
{
    int skip_x, skip_y;
    uint8_t r, g, b, Y;
    uint8_t *srcPtr = img;
    int l = strlen(brightness) - 1;

    skip_x = RATIO;
    skip_y = RATIO;
    for (int i = 0; i < IMAGE_SIZE_Y; i++) {
        for (int j = 0; j < IMAGE_SIZE_X; j++) {
            r = *srcPtr++ ^ 0x80;
            g = *srcPtr++ ^ 0x80;
            b = *srcPtr++ ^ 0x80;
            srcPtr++;
            Y = (3 * r + b + 4 * g) >> 3;
            if ((skip_x == RATIO) && (skip_y == RATIO))
                printf("%c", brightness[l - (Y * l / 255)]);

            skip_x++;
            if (skip_x > RATIO) skip_x = 1;
        }
        skip_y++;
        if (skip_y > RATIO) {
            printf("\n");
            skip_y = 1;
        }
    }
}
#endif

/* **************************************************************************** */
#ifdef TFT_ENABLE
void TFT_Print(char *str, int x, int y, int font, int length)
{
    text_t text;
    text.data = str;
    text.len = length;
    MXC_TFT_PrintFont(x, y, font, &text, NULL);
}

int g_dma_channel_tft = 1;
void setup_dma_tft(uint32_t *src_ptr, uint16_t byte_cnt)
{
    while ((MXC_DMA->ch[g_dma_channel_tft].status & MXC_F_DMA_STATUS_STATUS)) {}

    MXC_DMA->ch[g_dma_channel_tft].status = MXC_F_DMA_STATUS_CTZ_IF;
    MXC_DMA->ch[g_dma_channel_tft].dst = (uint32_t)data565;
    MXC_DMA->ch[g_dma_channel_tft].src = (uint32_t)src_ptr;
    MXC_DMA->ch[g_dma_channel_tft].cnt = byte_cnt;

    MXC_DMA->ch[g_dma_channel_tft].ctrl =
        ((0x1 << MXC_F_DMA_CTRL_CTZ_IE_POS) +
         (0x0 << MXC_F_DMA_CTRL_DIS_IE_POS) +
         (0x1 << MXC_F_DMA_CTRL_BURST_SIZE_POS) +
         (0x0 << MXC_F_DMA_CTRL_DSTINC_POS) +
         (0x1 << MXC_F_DMA_CTRL_DSTWD_POS) +
         (0x1 << MXC_F_DMA_CTRL_SRCINC_POS) +
         (0x1 << MXC_F_DMA_CTRL_SRCWD_POS) +
         (0x0 << MXC_F_DMA_CTRL_TO_CLKDIV_POS) +
         (0x0 << MXC_F_DMA_CTRL_TO_WAIT_POS) +
         (0x2F << MXC_F_DMA_CTRL_REQUEST_POS) +
         (0x0 << MXC_F_DMA_CTRL_PRI_POS) +
         (0x0 << MXC_F_DMA_CTRL_RLDEN_POS));

    MXC_SPI0->ctrl0 &= ~(MXC_F_SPI_CTRL0_EN);
    MXC_SETFIELD(MXC_SPI0->ctrl1, MXC_F_SPI_CTRL1_TX_NUM_CHAR,
                 byte_cnt << MXC_F_SPI_CTRL1_TX_NUM_CHAR_POS);
    MXC_SPI0->dma |= (MXC_F_SPI_DMA_TX_FLUSH | MXC_F_SPI_DMA_RX_FLUSH);
    MXC_SPI0->intfl = MXC_F_SPI_INTFL_MST_DONE;
    MXC_SETFIELD(MXC_SPI0->dma, MXC_F_DMA_CTRL_EN_POS, 0x10);
    MXC_SPI0->ctrl0 |= MXC_F_SPI_CTRL0_EN;
}

void tft_dma_display(int x, int y, int w, int h, uint32_t *data)
{
    setup_dma_tft(data, w * h * 2);
    MXC_DMA->ch[g_dma_channel_tft].ctrl |= (0x1 << MXC_F_DMA_CTRL_EN_POS);
    MXC_Delay(1);
    MXC_SPI0->ctrl0 |= MXC_F_SPI_CTRL0_START;
}
#endif

/* **************************************************************************** */
void fail(void)
{
    printf("\n*** FAIL ***\n\n");
    while (1) {}
}

/* **************************************************************************** */
void capture_process_camera(void)
{
    uint8_t *raw, *data;
    uint32_t imgLen, w, h;
    int cnt = 0;
    uint8_t r, g, b;
    uint16_t rgb;
    int j;

    stream_stat_t *stat;

    camera_start_capture_image();
    camera_get_image(&raw, &imgLen, &w, &h);
    printf("W:%d H:%d L:%d \n", w, h, imgLen);

#if defined(TFT_ENABLE) && defined(BOARD_FTHR_REVA)
    MXC_TFT_Stream(TFT_X_START, TFT_Y_START, w, h);
#endif

    for (int row = 0; row < h; row++) {
        while ((data = get_camera_stream_buffer()) == NULL) {
            if (camera_is_image_rcv()) break;
        }

#ifdef BOARD_EVKIT_V1
        j = IMAGE_SIZE_X * 2 - 2;
#else
        j = 0;
#endif

        for (int k = 0; k < 4 * w; k += 4) {
            r = data[k];
            g = data[k + 1];
            b = data[k + 2];
            input_0[cnt++] = ((b << 16) | (g << 8) | r) ^ 0x00808080;
            rgb = ((r & 0b11111000) << 8) | ((g & 0b11111100) << 3) | (b >> 3);
            data565[j] = (rgb >> 8) & 0xFF;
            data565[j + 1] = rgb & 0xFF;

#ifdef BOARD_EVKIT_V1
            j -= 2;
#else
            j += 2;
#endif
        }

#ifdef TFT_ENABLE
#ifdef BOARD_EVKIT_V1
        MXC_TFT_ShowImageCameraRGB565(TFT_X_START, TFT_Y_START + row, data565, w, 1);
#endif
#ifdef BOARD_FTHR_REVA
        tft_dma_display(TFT_X_START, TFT_Y_START + row, w, 1, (uint32_t *)data565);
#endif
#endif
        release_camera_stream_buffer();
    }

    stat = get_camera_stream_statistic();
    if (stat->overflow_count > 0) {
        printf("OVERFLOW DISP = %d\n", stat->overflow_count);
        LED_On(LED2);
        while (1) {}
    }
}

/* **************************************************************************** */
int main(void)
{
    int i, digs, tens, result[CNN_NUM_OUTPUTS];
    int ret, dma_channel;
    char buff[TFT_BUFF_SIZE];

    MXC_ICC_Enable(MXC_ICC0);
    MXC_SYS_Clock_Select(MXC_SYS_CLOCK_IPO);
    SystemCoreClockUpdate();

    printf("\n\nEyes Classification Demo\n");

    MXC_DMA_Init();
    dma_channel = MXC_DMA_AcquireChannel();

    MXC_Delay(200000);
    Camera_Power(POWER_ON);

    cnn_enable(MXC_S_GCR_PCLKDIV_CNNCLKSEL_PCLK, MXC_S_GCR_PCLKDIV_CNNCLKDIV_DIV1);
    cnn_init();
    cnn_load_weights();
    cnn_load_bias();
    cnn_configure();

#ifdef TFT_ENABLE
    MXC_TFT_Init(MXC_SPI0, 1, NULL, NULL);
    MXC_TFT_SetRotation(ROTATE_270);
    MXC_TFT_ShowImage(0, 0, image_bitmap_1);
    MXC_TFT_SetForeGroundColor(WHITE);
    MXC_Delay(1000000);
    memset(buff, 32, TFT_BUFF_SIZE);
    TFT_Print(buff, 55, 50, font_2, snprintf(buff, sizeof(buff), "ANALOG DEVICES"));
    TFT_Print(buff, 55, 90, font_1, snprintf(buff, sizeof(buff), "Eyes Demo"));
    TFT_Print(buff, 20, 130, font_2, snprintf(buff, sizeof(buff), "PRESS PB1(SW1) TO START!"));
#endif

    printf("********** Press PB1(SW1) to capture an image **********\r\n");
    while (!PB_Get(0)) {}

#ifdef TFT_ENABLE
    MXC_TFT_ClearScreen();
#endif

    camera_init(CAMERA_FREQ);
    ret = camera_setup(IMAGE_SIZE_X, IMAGE_SIZE_Y, PIXFORMAT_RGB888, FIFO_THREE_BYTE, STREAMING_DMA, dma_channel);
    if (ret != STATUS_OK) {
        printf("Error returned from camera_setup %d\n", ret);
        return -1;
    }

#ifdef BOARD_EVKIT_V1
    camera_write_reg(0x11, 0x1);
#endif
#ifdef BOARD_FTHR_REVA
    camera_write_reg(0x11, 0x0);
#endif

    MXC_SYS_ClockEnable(MXC_SYS_PERIPH_CLOCK_CNN);

    while (1) {
        LED_Off(LED1);
        LED_Off(LED2);

        capture_process_camera();

        cnn_start();
        // Load camera buffer into CNN
        for (i = 0; i < IMAGE_SIZE_X * IMAGE_SIZE_Y; i++) {
            while (((*((volatile uint32_t *)0x50000004) & 1)) != 0) {}
            *((volatile uint32_t *)0x50000008) = input_0[i];
        }

        while (cnn_time == 0) __WFI();

        cnn_unload((uint32_t *)ml_data);
        cnn_stop();
        softmax_q17p14_q15((const q31_t *)ml_data, CNN_NUM_OUTPUTS, ml_softmax);

        printf("Time for CNN: %d us\n\n", cnn_time);

        printf("Classification results:\n");
        for (i = 0; i < CNN_NUM_OUTPUTS; i++) {
            digs = (1000 * ml_softmax[i] + 0x4000) >> 15;
            tens = digs % 10;
            digs = digs / 10;
            result[i] = digs;
            printf("[%7d] -> Class %d %8s: %d.%d%%\r\n", ml_data[i], i, classes[i], result[i], tens);
        }

#ifdef ASCII_ART
        asciiart((uint8_t *)input_0);
#endif

#ifdef TFT_ENABLE
        memset(buff, 32, TFT_BUFF_SIZE);
        if (ml_data[0] > ml_data[1]) {
            TFT_Print(buff, TFT_X_START + 10, TFT_Y_START - 30, font_1,
                      snprintf(buff, sizeof(buff), "%s (%d%%)", classes[0], result[0]));
            LED_On(LED1); LED_Off(LED2);
        } else {
            TFT_Print(buff, TFT_X_START + 10, TFT_Y_START - 30, font_1,
                      snprintf(buff, sizeof(buff), "%s (%d%%)", classes[1], result[1]));
            LED_Off(LED1); LED_On(LED2);
        }
        TFT_Print(buff, TFT_X_START + 40, TFT_Y_START + IMAGE_SIZE_Y + 10, font_1,
                  snprintf(buff, sizeof(buff), "%dms", cnn_time / 1000));
        TFT_Print(buff, 20, TFT_Y_START + IMAGE_SIZE_Y + 35, font_2,
                  snprintf(buff, sizeof(buff), "PRESS PB1(SW1) TO CAPTURE"));
#endif

        printf("********** Press PB1(SW1) to capture an image **********\r\n");
        while (!PB_Get(0)) {}
    }

    return 0;
}
